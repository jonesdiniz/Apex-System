#!/usr/bin/env python3
"""
Proactive Mitigation Engine v4.0
M√≥dulo de Mitiga√ß√£o Proativa para Immune System v4.0

Este m√≥dulo implementa capacidades avan√ßadas de preven√ß√£o de falhas:
- Detec√ß√£o preditiva de falhas iminentes
- Prepara√ß√£o autom√°tica de hot standby instances
- Transi√ß√£o seamless para preven√ß√£o de downtime
- Orquestra√ß√£o inteligente de a√ß√µes preventivas

Autor: Manus AI
Data: 11 de Julho de 2025
Vers√£o: 4.0.0
"""

import asyncio
import aiohttp
import json
import time
import logging
import random
import statistics
import numpy as np
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import uuid

# ============================================================================
# CONFIGURA√á√ÉO DE LOGGING
# ============================================================================

logging.basicConfig(
    level=logging.INFO,
    format='{"timestamp": "%(asctime)s", "level": "%(levelname)s", "service": "proactive-mitigation-v4", "message": "%(message)s"}',
    datefmt='%Y-%m-%dT%H:%M:%S'
)
logger = logging.getLogger(__name__)

# ============================================================================
# MODELOS DE DADOS PARA MITIGA√á√ÉO PROATIVA
# ============================================================================

class FailureType(Enum):
    """Tipos de falhas que podem ser preditas"""
    MEMORY_LEAK = "memory_leak"
    CPU_OVERLOAD = "cpu_overload"
    DISK_FULL = "disk_full"
    NETWORK_CONGESTION = "network_congestion"
    DATABASE_DEADLOCK = "database_deadlock"
    SERVICE_CRASH = "service_crash"
    DEPENDENCY_FAILURE = "dependency_failure"
    RESOURCE_EXHAUSTION = "resource_exhaustion"

class MitigationStrategy(Enum):
    """Estrat√©gias de mitiga√ß√£o dispon√≠veis"""
    HOT_STANDBY_REPLACEMENT = "hot_standby_replacement"
    GRACEFUL_RESTART = "graceful_restart"
    LOAD_REDISTRIBUTION = "load_redistribution"
    RESOURCE_SCALING = "resource_scaling"
    CIRCUIT_BREAKER_ACTIVATION = "circuit_breaker_activation"
    DEPENDENCY_ISOLATION = "dependency_isolation"
    CACHE_WARMING = "cache_warming"
    TRAFFIC_THROTTLING = "traffic_throttling"

class PreventionStatus(Enum):
    """Status da preven√ß√£o"""
    MONITORING = "monitoring"
    FAILURE_PREDICTED = "failure_predicted"
    MITIGATION_PREPARING = "mitigation_preparing"
    MITIGATION_EXECUTING = "mitigation_executing"
    MITIGATION_COMPLETED = "mitigation_completed"
    MITIGATION_FAILED = "mitigation_failed"
    ROLLBACK_REQUIRED = "rollback_required"

@dataclass
class FailurePrediction:
    """Predi√ß√£o de falha iminente"""
    id: str
    service_name: str
    failure_type: FailureType
    predicted_time: datetime
    confidence: float
    time_to_failure_minutes: int
    contributing_factors: List[str]
    severity: str  # "low", "medium", "high", "critical"
    impact_assessment: Dict[str, Any]
    recommended_strategy: MitigationStrategy
    created_at: datetime

@dataclass
class ProactiveMitigation:
    """A√ß√£o de mitiga√ß√£o proativa"""
    id: str
    prediction_id: str
    service_name: str
    strategy: MitigationStrategy
    status: PreventionStatus
    confidence: float
    estimated_duration: int
    preparation_steps: List[str]
    execution_steps: List[str]
    rollback_steps: List[str]
    resources_required: Dict[str, Any]
    dependencies: List[str]
    created_at: datetime
    started_at: Optional[datetime] = None
    completed_at: Optional[datetime] = None
    result: Optional[Dict[str, Any]] = None
    error_message: Optional[str] = None

@dataclass
class ServiceHealthTrend:
    """Tend√™ncia de sa√∫de do servi√ßo para an√°lise preditiva"""
    service_name: str
    timestamp: datetime
    health_scores: List[float]  # √öltimos N health scores
    response_times: List[float]  # √öltimos N response times
    cpu_usage_trend: List[float]
    memory_usage_trend: List[float]
    error_rate_trend: List[float]
    throughput_trend: List[float]
    anomaly_scores: List[float]
    
    # M√©tricas derivadas
    health_velocity: float  # Taxa de mudan√ßa do health score
    performance_degradation: float  # Taxa de degrada√ß√£o de performance
    stability_index: float  # √çndice de estabilidade (0-1)
    failure_probability: float  # Probabilidade de falha (0-1)

# ============================================================================
# FAILURE PREDICTION ENGINE - PREDITOR DE FALHAS
# ============================================================================

class FailurePredictionEngine:
    """Engine de predi√ß√£o de falhas baseado em ML e an√°lise de tend√™ncias"""
    
    def __init__(self):
        self.prediction_models = {
            FailureType.MEMORY_LEAK: self._predict_memory_leak,
            FailureType.CPU_OVERLOAD: self._predict_cpu_overload,
            FailureType.SERVICE_CRASH: self._predict_service_crash,
            FailureType.RESOURCE_EXHAUSTION: self._predict_resource_exhaustion,
            FailureType.NETWORK_CONGESTION: self._predict_network_congestion
        }
        
        self.historical_data = {}
        self.prediction_accuracy = {}
        self.confidence_thresholds = {
            "critical": 0.95,
            "high": 0.85,
            "medium": 0.70,
            "low": 0.50
        }
    
    async def analyze_service_trends(self, service_name: str, metrics_history: List[Dict[str, Any]]) -> ServiceHealthTrend:
        """Analisar tend√™ncias de sa√∫de do servi√ßo"""
        
        if len(metrics_history) < 5:
            # Dados insuficientes para an√°lise
            return self._create_default_trend(service_name)
        
        # Extrair s√©ries temporais
        health_scores = [m.get("health_score", 0) for m in metrics_history[-20:]]
        response_times = [m.get("response_time_ms", 0) for m in metrics_history[-20:]]
        cpu_usage = [m.get("cpu_usage_percent", 0) for m in metrics_history[-20:]]
        memory_usage = [m.get("memory_usage_percent", 0) for m in metrics_history[-20:]]
        error_rates = [m.get("error_rate_percent", 0) for m in metrics_history[-20:]]
        throughput = [m.get("throughput_rps", 0) for m in metrics_history[-20:]]
        anomaly_scores = [m.get("anomaly_score", 0) for m in metrics_history[-20:]]
        
        # Calcular m√©tricas derivadas
        health_velocity = self._calculate_velocity(health_scores)
        performance_degradation = self._calculate_performance_degradation(response_times, throughput)
        stability_index = self._calculate_stability_index(health_scores, error_rates)
        failure_probability = self._calculate_failure_probability(
            health_velocity, performance_degradation, stability_index, anomaly_scores
        )
        
        return ServiceHealthTrend(
            service_name=service_name,
            timestamp=datetime.now(),
            health_scores=health_scores,
            response_times=response_times,
            cpu_usage_trend=cpu_usage,
            memory_usage_trend=memory_usage,
            error_rate_trend=error_rates,
            throughput_trend=throughput,
            anomaly_scores=anomaly_scores,
            health_velocity=health_velocity,
            performance_degradation=performance_degradation,
            stability_index=stability_index,
            failure_probability=failure_probability
        )
    
    async def predict_failures(self, trend: ServiceHealthTrend) -> List[FailurePrediction]:
        """Predizer falhas baseado nas tend√™ncias"""
        
        predictions = []
        
        # Executar cada modelo de predi√ß√£o
        for failure_type, prediction_func in self.prediction_models.items():
            prediction = await prediction_func(trend)
            if prediction:
                predictions.append(prediction)
        
        # Ordenar por confian√ßa e tempo at√© falha
        predictions.sort(key=lambda p: (p.confidence, -p.time_to_failure_minutes), reverse=True)
        
        return predictions
    
    async def _predict_memory_leak(self, trend: ServiceHealthTrend) -> Optional[FailurePrediction]:
        """Predizer vazamento de mem√≥ria"""
        
        if len(trend.memory_usage_trend) < 5:
            return None
        
        # Analisar tend√™ncia de crescimento de mem√≥ria
        memory_growth_rate = self._calculate_growth_rate(trend.memory_usage_trend)
        current_memory = trend.memory_usage_trend[-1]
        
        # Predizer se mem√≥ria chegar√° a 95% em menos de 30 minutos
        if memory_growth_rate > 0 and current_memory > 60:
            time_to_95_percent = (95 - current_memory) / memory_growth_rate if memory_growth_rate > 0 else float('inf')
            
            if time_to_95_percent <= 30:  # 30 minutos
                confidence = min(0.95, 0.6 + (memory_growth_rate / 10) + ((current_memory - 60) / 100))
                
                return FailurePrediction(
                    id=f"memory_leak_{trend.service_name}_{int(time.time())}",
                    service_name=trend.service_name,
                    failure_type=FailureType.MEMORY_LEAK,
                    predicted_time=datetime.now() + timedelta(minutes=int(time_to_95_percent)),
                    confidence=confidence,
                    time_to_failure_minutes=int(time_to_95_percent),
                    contributing_factors=[
                        f"Memory usage growing at {memory_growth_rate:.2f}%/min",
                        f"Current memory usage: {current_memory:.1f}%",
                        "Sustained upward trend detected"
                    ],
                    severity="high" if confidence > 0.8 else "medium",
                    impact_assessment={
                        "service_availability": "critical",
                        "performance_impact": "severe",
                        "user_experience": "degraded"
                    },
                    recommended_strategy=MitigationStrategy.HOT_STANDBY_REPLACEMENT,
                    created_at=datetime.now()
                )
        
        return None
    
    async def _predict_cpu_overload(self, trend: ServiceHealthTrend) -> Optional[FailurePrediction]:
        """Predizer sobrecarga de CPU"""
        
        if len(trend.cpu_usage_trend) < 5:
            return None
        
        current_cpu = trend.cpu_usage_trend[-1]
        cpu_growth_rate = self._calculate_growth_rate(trend.cpu_usage_trend)
        
        # Predizer se CPU chegar√° a 95% em menos de 20 minutos
        if current_cpu > 70 and cpu_growth_rate > 0:
            time_to_95_percent = (95 - current_cpu) / cpu_growth_rate if cpu_growth_rate > 0 else float('inf')
            
            if time_to_95_percent <= 20:  # 20 minutos
                confidence = min(0.92, 0.7 + (cpu_growth_rate / 15) + ((current_cpu - 70) / 100))
                
                return FailurePrediction(
                    id=f"cpu_overload_{trend.service_name}_{int(time.time())}",
                    service_name=trend.service_name,
                    failure_type=FailureType.CPU_OVERLOAD,
                    predicted_time=datetime.now() + timedelta(minutes=int(time_to_95_percent)),
                    confidence=confidence,
                    time_to_failure_minutes=int(time_to_95_percent),
                    contributing_factors=[
                        f"CPU usage growing at {cpu_growth_rate:.2f}%/min",
                        f"Current CPU usage: {current_cpu:.1f}%",
                        "High load trend detected"
                    ],
                    severity="high" if confidence > 0.8 else "medium",
                    impact_assessment={
                        "service_availability": "high",
                        "performance_impact": "severe",
                        "response_time": "degraded"
                    },
                    recommended_strategy=MitigationStrategy.RESOURCE_SCALING,
                    created_at=datetime.now()
                )
        
        return None
    
    async def _predict_service_crash(self, trend: ServiceHealthTrend) -> Optional[FailurePrediction]:
        """Predizer crash de servi√ßo"""
        
        # Analisar m√∫ltiplos indicadores de instabilidade
        health_declining = trend.health_velocity < -2  # Health score caindo rapidamente
        high_error_rate = trend.error_rate_trend[-1] > 10 if trend.error_rate_trend else False
        performance_degrading = trend.performance_degradation > 0.5
        high_anomaly = trend.anomaly_scores[-1] > 4 if trend.anomaly_scores else False
        
        instability_factors = sum([health_declining, high_error_rate, performance_degrading, high_anomaly])
        
        if instability_factors >= 3:  # M√∫ltiplos indicadores de problema
            confidence = min(0.88, 0.5 + (instability_factors * 0.15) + (trend.failure_probability * 0.3))
            time_to_failure = max(5, int(20 - (instability_factors * 5)))  # 5-15 minutos
            
            return FailurePrediction(
                id=f"service_crash_{trend.service_name}_{int(time.time())}",
                service_name=trend.service_name,
                failure_type=FailureType.SERVICE_CRASH,
                predicted_time=datetime.now() + timedelta(minutes=time_to_failure),
                confidence=confidence,
                time_to_failure_minutes=time_to_failure,
                contributing_factors=[
                    f"Health score declining rapidly: {trend.health_velocity:.2f}/min",
                    f"Error rate: {trend.error_rate_trend[-1]:.1f}%" if trend.error_rate_trend else "Error rate elevated",
                    f"Performance degradation: {trend.performance_degradation:.2f}",
                    f"Anomaly score: {trend.anomaly_scores[-1]:.1f}" if trend.anomaly_scores else "High anomaly detected"
                ],
                severity="critical" if confidence > 0.8 else "high",
                impact_assessment={
                    "service_availability": "critical",
                    "performance_impact": "complete_failure",
                    "user_experience": "service_unavailable"
                },
                recommended_strategy=MitigationStrategy.HOT_STANDBY_REPLACEMENT,
                created_at=datetime.now()
            )
        
        return None
    
    async def _predict_resource_exhaustion(self, trend: ServiceHealthTrend) -> Optional[FailurePrediction]:
        """Predizer esgotamento de recursos"""
        
        # Analisar m√∫ltiplos recursos
        memory_critical = trend.memory_usage_trend[-1] > 85 if trend.memory_usage_trend else False
        cpu_critical = trend.cpu_usage_trend[-1] > 85 if trend.cpu_usage_trend else False
        performance_degraded = trend.performance_degradation > 0.4
        
        if memory_critical and cpu_critical:
            confidence = 0.85 + (trend.performance_degradation * 0.1)
            time_to_failure = 10  # 10 minutos para esgotamento completo
            
            return FailurePrediction(
                id=f"resource_exhaustion_{trend.service_name}_{int(time.time())}",
                service_name=trend.service_name,
                failure_type=FailureType.RESOURCE_EXHAUSTION,
                predicted_time=datetime.now() + timedelta(minutes=time_to_failure),
                confidence=confidence,
                time_to_failure_minutes=time_to_failure,
                contributing_factors=[
                    f"Memory usage critical: {trend.memory_usage_trend[-1]:.1f}%",
                    f"CPU usage critical: {trend.cpu_usage_trend[-1]:.1f}%",
                    f"Performance degradation: {trend.performance_degradation:.2f}"
                ],
                severity="critical",
                impact_assessment={
                    "service_availability": "critical",
                    "performance_impact": "severe",
                    "resource_utilization": "exhausted"
                },
                recommended_strategy=MitigationStrategy.RESOURCE_SCALING,
                created_at=datetime.now()
            )
        
        return None
    
    async def _predict_network_congestion(self, trend: ServiceHealthTrend) -> Optional[FailurePrediction]:
        """Predizer congestionamento de rede"""
        
        # Analisar response times e throughput
        if len(trend.response_times) < 5 or len(trend.throughput_trend) < 5:
            return None
        
        response_time_growth = self._calculate_growth_rate(trend.response_times)
        throughput_decline = -self._calculate_growth_rate(trend.throughput_trend)
        current_response_time = trend.response_times[-1]
        
        if current_response_time > 500 and response_time_growth > 10 and throughput_decline > 0.1:
            confidence = min(0.80, 0.6 + (response_time_growth / 100) + (throughput_decline * 2))
            time_to_failure = 15  # 15 minutos para congestionamento cr√≠tico
            
            return FailurePrediction(
                id=f"network_congestion_{trend.service_name}_{int(time.time())}",
                service_name=trend.service_name,
                failure_type=FailureType.NETWORK_CONGESTION,
                predicted_time=datetime.now() + timedelta(minutes=time_to_failure),
                confidence=confidence,
                time_to_failure_minutes=time_to_failure,
                contributing_factors=[
                    f"Response time growing: {response_time_growth:.2f}ms/min",
                    f"Throughput declining: {throughput_decline:.2f}rps/min",
                    f"Current response time: {current_response_time:.1f}ms"
                ],
                severity="high",
                impact_assessment={
                    "service_availability": "degraded",
                    "performance_impact": "high",
                    "network_performance": "congested"
                },
                recommended_strategy=MitigationStrategy.LOAD_REDISTRIBUTION,
                created_at=datetime.now()
            )
        
        return None
    
    def _calculate_velocity(self, values: List[float]) -> float:
        """Calcular velocidade de mudan√ßa (derivada)"""
        if len(values) < 2:
            return 0.0
        
        # Calcular diferen√ßas consecutivas
        diffs = [values[i] - values[i-1] for i in range(1, len(values))]
        return statistics.mean(diffs) if diffs else 0.0
    
    def _calculate_growth_rate(self, values: List[float]) -> float:
        """Calcular taxa de crescimento por minuto"""
        if len(values) < 2:
            return 0.0
        
        # Regress√£o linear simples para taxa de crescimento
        n = len(values)
        x = list(range(n))
        y = values
        
        # Calcular slope (taxa de crescimento)
        x_mean = statistics.mean(x)
        y_mean = statistics.mean(y)
        
        numerator = sum((x[i] - x_mean) * (y[i] - y_mean) for i in range(n))
        denominator = sum((x[i] - x_mean) ** 2 for i in range(n))
        
        if denominator == 0:
            return 0.0
        
        slope = numerator / denominator
        return slope  # Taxa de crescimento por per√≠odo
    
    def _calculate_performance_degradation(self, response_times: List[float], throughput: List[float]) -> float:
        """Calcular √≠ndice de degrada√ß√£o de performance"""
        if not response_times or not throughput:
            return 0.0
        
        # Normalizar response time (maior = pior)
        rt_degradation = (response_times[-1] - min(response_times)) / max(response_times) if max(response_times) > 0 else 0
        
        # Normalizar throughput (menor = pior)
        tp_degradation = (max(throughput) - throughput[-1]) / max(throughput) if max(throughput) > 0 else 0
        
        return (rt_degradation + tp_degradation) / 2
    
    def _calculate_stability_index(self, health_scores: List[float], error_rates: List[float]) -> float:
        """Calcular √≠ndice de estabilidade (0-1, 1 = mais est√°vel)"""
        if not health_scores:
            return 0.5
        
        # Variabilidade do health score (menor = mais est√°vel)
        health_stability = 1 - (statistics.stdev(health_scores) / 100) if len(health_scores) > 1 else 1
        
        # Taxa de erro (menor = mais est√°vel)
        error_stability = 1 - (error_rates[-1] / 100) if error_rates else 1
        
        return max(0, min(1, (health_stability + error_stability) / 2))
    
    def _calculate_failure_probability(self, health_velocity: float, performance_degradation: float, 
                                     stability_index: float, anomaly_scores: List[float]) -> float:
        """Calcular probabilidade de falha (0-1)"""
        
        # Fatores de risco
        health_risk = max(0, -health_velocity / 10)  # Health score caindo
        performance_risk = performance_degradation
        stability_risk = 1 - stability_index
        anomaly_risk = (anomaly_scores[-1] / 10) if anomaly_scores else 0
        
        # M√©dia ponderada
        failure_prob = (health_risk * 0.3 + performance_risk * 0.3 + 
                       stability_risk * 0.25 + anomaly_risk * 0.15)
        
        return max(0, min(1, failure_prob))
    
    def _create_default_trend(self, service_name: str) -> ServiceHealthTrend:
        """Criar tend√™ncia padr√£o quando n√£o h√° dados suficientes"""
        return ServiceHealthTrend(
            service_name=service_name,
            timestamp=datetime.now(),
            health_scores=[80.0],
            response_times=[100.0],
            cpu_usage_trend=[30.0],
            memory_usage_trend=[40.0],
            error_rate_trend=[1.0],
            throughput_trend=[1.0],
            anomaly_scores=[1.0],
            health_velocity=0.0,
            performance_degradation=0.0,
            stability_index=0.8,
            failure_probability=0.1
        )

# ============================================================================
# PROACTIVE MITIGATION ORCHESTRATOR - ORQUESTRADOR DE MITIGA√á√ÉO
# ============================================================================

class ProactiveMitigationOrchestrator:
    """Orquestrador de a√ß√µes de mitiga√ß√£o proativa"""
    
    def __init__(self):
        self.active_mitigations = {}
        self.mitigation_history = []
        self.strategy_implementations = {
            MitigationStrategy.HOT_STANDBY_REPLACEMENT: self._execute_hot_standby_replacement,
            MitigationStrategy.GRACEFUL_RESTART: self._execute_graceful_restart,
            MitigationStrategy.LOAD_REDISTRIBUTION: self._execute_load_redistribution,
            MitigationStrategy.RESOURCE_SCALING: self._execute_resource_scaling,
            MitigationStrategy.CIRCUIT_BREAKER_ACTIVATION: self._execute_circuit_breaker,
            MitigationStrategy.TRAFFIC_THROTTLING: self._execute_traffic_throttling
        }
        
        # Simulador de infraestrutura
        self.infrastructure_api = InfrastructureAPISimulator()
    
    async def create_mitigation_plan(self, prediction: FailurePrediction) -> ProactiveMitigation:
        """Criar plano de mitiga√ß√£o baseado na predi√ß√£o"""
        
        strategy = prediction.recommended_strategy
        
        # Definir steps baseado na estrat√©gia
        preparation_steps, execution_steps, rollback_steps = self._define_mitigation_steps(strategy, prediction)
        
        # Estimar recursos necess√°rios
        resources_required = self._estimate_required_resources(strategy, prediction)
        
        # Identificar depend√™ncias
        dependencies = self._identify_dependencies(prediction.service_name, strategy)
        
        mitigation = ProactiveMitigation(
            id=f"mitigation_{prediction.service_name}_{int(time.time())}",
            prediction_id=prediction.id,
            service_name=prediction.service_name,
            strategy=strategy,
            status=PreventionStatus.MONITORING,
            confidence=prediction.confidence,
            estimated_duration=self._estimate_mitigation_duration(strategy),
            preparation_steps=preparation_steps,
            execution_steps=execution_steps,
            rollback_steps=rollback_steps,
            resources_required=resources_required,
            dependencies=dependencies,
            created_at=datetime.now()
        )
        
        return mitigation
    
    async def execute_mitigation(self, mitigation: ProactiveMitigation) -> Dict[str, Any]:
        """Executar mitiga√ß√£o proativa"""
        
        logger.info(f"üõ°Ô∏è Iniciando mitiga√ß√£o proativa para {mitigation.service_name}: {mitigation.strategy.value}")
        
        mitigation.status = PreventionStatus.MITIGATION_PREPARING
        mitigation.started_at = datetime.now()
        self.active_mitigations[mitigation.id] = mitigation
        
        try:
            # Fase 1: Prepara√ß√£o
            prep_result = await self._execute_preparation_phase(mitigation)
            if not prep_result["success"]:
                mitigation.status = PreventionStatus.MITIGATION_FAILED
                mitigation.error_message = prep_result["error"]
                return prep_result
            
            # Fase 2: Execu√ß√£o
            mitigation.status = PreventionStatus.MITIGATION_EXECUTING
            exec_result = await self._execute_mitigation_phase(mitigation)
            
            if exec_result["success"]:
                mitigation.status = PreventionStatus.MITIGATION_COMPLETED
                mitigation.result = exec_result
                mitigation.completed_at = datetime.now()
                
                logger.info(f"‚úÖ Mitiga√ß√£o proativa conclu√≠da para {mitigation.service_name}")
                
                # Monitorar resultado
                await self._monitor_mitigation_result(mitigation)
                
                return exec_result
            else:
                # Execu√ß√£o falhou, tentar rollback
                mitigation.status = PreventionStatus.ROLLBACK_REQUIRED
                mitigation.error_message = exec_result.get("error", "Unknown error")
                
                logger.error(f"‚ùå Mitiga√ß√£o falhou para {mitigation.service_name}: {mitigation.error_message}")
                
                # Tentar rollback
                await self._attempt_mitigation_rollback(mitigation)
                
                return exec_result
                
        except Exception as e:
            mitigation.status = PreventionStatus.MITIGATION_FAILED
            mitigation.error_message = str(e)
            logger.error(f"‚ùå Erro inesperado na mitiga√ß√£o {mitigation.id}: {str(e)}")
            
            return {"success": False, "error": str(e)}
        
        finally:
            mitigation.completed_at = datetime.now()
            self.mitigation_history.append(mitigation)
            if mitigation.id in self.active_mitigations:
                del self.active_mitigations[mitigation.id]
    
    async def _execute_preparation_phase(self, mitigation: ProactiveMitigation) -> Dict[str, Any]:
        """Executar fase de prepara√ß√£o"""
        
        logger.info(f"üîß Preparando mitiga√ß√£o {mitigation.strategy.value} para {mitigation.service_name}")
        
        try:
            for step in mitigation.preparation_steps:
                logger.info(f"  üìã Executando: {step}")
                await asyncio.sleep(1)  # Simular tempo de prepara√ß√£o
            
            return {"success": True, "message": "Preparation completed successfully"}
            
        except Exception as e:
            return {"success": False, "error": f"Preparation failed: {str(e)}"}
    
    async def _execute_mitigation_phase(self, mitigation: ProactiveMitigation) -> Dict[str, Any]:
        """Executar fase de mitiga√ß√£o"""
        
        strategy_func = self.strategy_implementations.get(mitigation.strategy)
        if not strategy_func:
            return {"success": False, "error": f"Strategy {mitigation.strategy.value} not implemented"}
        
        return await strategy_func(mitigation)
    
    async def _execute_hot_standby_replacement(self, mitigation: ProactiveMitigation) -> Dict[str, Any]:
        """Executar substitui√ß√£o por hot standby"""
        
        try:
            logger.info(f"üîÑ Executando hot standby replacement para {mitigation.service_name}")
            
            # Passo 1: Inicializar inst√¢ncia standby
            standby_result = await self.infrastructure_api.create_standby_instance(
                service_name=mitigation.service_name
            )
            
            if not standby_result["success"]:
                return standby_result
            
            standby_instance_id = standby_result["instance_id"]
            
            # Passo 2: Aguardar inst√¢ncia ficar pronta
            await asyncio.sleep(5)  # Simular tempo de inicializa√ß√£o
            
            # Passo 3: Validar sa√∫de da inst√¢ncia standby
            health_check = await self.infrastructure_api.validate_instance_health(standby_instance_id)
            
            if not health_check["healthy"]:
                return {"success": False, "error": "Standby instance failed health check"}
            
            # Passo 4: Transi√ß√£o de tr√°fego
            traffic_result = await self.infrastructure_api.switch_traffic_to_standby(
                service_name=mitigation.service_name,
                standby_instance_id=standby_instance_id
            )
            
            if not traffic_result["success"]:
                return traffic_result
            
            # Passo 5: Descomissionar inst√¢ncia original
            await asyncio.sleep(2)  # Aguardar estabiliza√ß√£o
            
            decommission_result = await self.infrastructure_api.decommission_original_instance(
                service_name=mitigation.service_name
            )
            
            logger.info(f"‚úÖ Hot standby replacement conclu√≠do para {mitigation.service_name}")
            
            return {
                "success": True,
                "action": "hot_standby_replacement_completed",
                "service": mitigation.service_name,
                "standby_instance_id": standby_instance_id,
                "traffic_switched": True,
                "original_decommissioned": decommission_result["success"],
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _execute_graceful_restart(self, mitigation: ProactiveMitigation) -> Dict[str, Any]:
        """Executar restart graceful"""
        
        try:
            logger.info(f"üîÑ Executando graceful restart para {mitigation.service_name}")
            
            # Passo 1: Drenar conex√µes existentes
            drain_result = await self.infrastructure_api.drain_connections(mitigation.service_name)
            
            if not drain_result["success"]:
                return drain_result
            
            # Passo 2: Aguardar drenagem completa
            await asyncio.sleep(3)
            
            # Passo 3: Restart do servi√ßo
            restart_result = await self.infrastructure_api.restart_service_gracefully(mitigation.service_name)
            
            if not restart_result["success"]:
                return restart_result
            
            # Passo 4: Aguardar inicializa√ß√£o
            await asyncio.sleep(5)
            
            # Passo 5: Validar sa√∫de p√≥s-restart
            health_check = await self.infrastructure_api.validate_service_health(mitigation.service_name)
            
            if not health_check["healthy"]:
                return {"success": False, "error": "Service failed health check after restart"}
            
            logger.info(f"‚úÖ Graceful restart conclu√≠do para {mitigation.service_name}")
            
            return {
                "success": True,
                "action": "graceful_restart_completed",
                "service": mitigation.service_name,
                "connections_drained": drain_result["connections_drained"],
                "restart_time": restart_result["restart_time"],
                "health_validated": True,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _execute_load_redistribution(self, mitigation: ProactiveMitigation) -> Dict[str, Any]:
        """Executar redistribui√ß√£o de carga"""
        
        try:
            logger.info(f"‚öñÔ∏è Executando load redistribution para {mitigation.service_name}")
            
            # Passo 1: Analisar carga atual
            load_analysis = await self.infrastructure_api.analyze_current_load(mitigation.service_name)
            
            # Passo 2: Identificar inst√¢ncias com menor carga
            redistribution_plan = await self.infrastructure_api.create_redistribution_plan(
                service_name=mitigation.service_name,
                current_load=load_analysis["load_distribution"]
            )
            
            # Passo 3: Executar redistribui√ß√£o gradual
            redistribution_result = await self.infrastructure_api.execute_load_redistribution(
                redistribution_plan
            )
            
            if not redistribution_result["success"]:
                return redistribution_result
            
            # Passo 4: Monitorar estabiliza√ß√£o
            await asyncio.sleep(3)
            
            # Passo 5: Validar nova distribui√ß√£o
            validation_result = await self.infrastructure_api.validate_load_distribution(
                mitigation.service_name
            )
            
            logger.info(f"‚úÖ Load redistribution conclu√≠do para {mitigation.service_name}")
            
            return {
                "success": True,
                "action": "load_redistribution_completed",
                "service": mitigation.service_name,
                "previous_load": load_analysis["load_distribution"],
                "new_load": validation_result["load_distribution"],
                "improvement": validation_result["load_balance_improvement"],
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _execute_resource_scaling(self, mitigation: ProactiveMitigation) -> Dict[str, Any]:
        """Executar scaling de recursos"""
        
        try:
            logger.info(f"üìà Executando resource scaling para {mitigation.service_name}")
            
            # Determinar tipo de scaling necess√°rio
            scaling_type = "vertical"  # CPU/Memory
            if "instances" in mitigation.resources_required:
                scaling_type = "horizontal"  # N√∫mero de inst√¢ncias
            
            if scaling_type == "horizontal":
                result = await self.infrastructure_api.scale_instances(
                    service_name=mitigation.service_name,
                    target_instances=mitigation.resources_required.get("instances", 2)
                )
            else:
                result = await self.infrastructure_api.scale_resources(
                    service_name=mitigation.service_name,
                    cpu_limit=mitigation.resources_required.get("cpu", "2000m"),
                    memory_limit=mitigation.resources_required.get("memory", "4Gi")
                )
            
            if not result["success"]:
                return result
            
            # Aguardar aplica√ß√£o do scaling
            await asyncio.sleep(4)
            
            # Validar resultado
            validation = await self.infrastructure_api.validate_scaling_result(
                mitigation.service_name, scaling_type
            )
            
            logger.info(f"‚úÖ Resource scaling conclu√≠do para {mitigation.service_name}")
            
            return {
                "success": True,
                "action": "resource_scaling_completed",
                "service": mitigation.service_name,
                "scaling_type": scaling_type,
                "resources_allocated": result["resources_allocated"],
                "performance_improvement": validation["performance_improvement"],
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _execute_circuit_breaker(self, mitigation: ProactiveMitigation) -> Dict[str, Any]:
        """Executar ativa√ß√£o de circuit breaker"""
        
        try:
            logger.info(f"üîå Executando circuit breaker activation para {mitigation.service_name}")
            
            # Ativar circuit breaker para depend√™ncias problem√°ticas
            activation_result = await self.infrastructure_api.activate_circuit_breaker(
                service_name=mitigation.service_name,
                dependencies=mitigation.dependencies
            )
            
            if not activation_result["success"]:
                return activation_result
            
            # Configurar fallback responses
            fallback_result = await self.infrastructure_api.configure_fallback_responses(
                mitigation.service_name
            )
            
            logger.info(f"‚úÖ Circuit breaker activation conclu√≠do para {mitigation.service_name}")
            
            return {
                "success": True,
                "action": "circuit_breaker_activated",
                "service": mitigation.service_name,
                "protected_dependencies": activation_result["protected_dependencies"],
                "fallback_configured": fallback_result["success"],
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def _execute_traffic_throttling(self, mitigation: ProactiveMitigation) -> Dict[str, Any]:
        """Executar throttling de tr√°fego"""
        
        try:
            logger.info(f"üö¶ Executando traffic throttling para {mitigation.service_name}")
            
            # Implementar rate limiting
            throttling_result = await self.infrastructure_api.implement_rate_limiting(
                service_name=mitigation.service_name,
                rate_limit=mitigation.resources_required.get("rate_limit", "100/min")
            )
            
            if not throttling_result["success"]:
                return throttling_result
            
            # Configurar queue management
            queue_result = await self.infrastructure_api.configure_request_queue(
                mitigation.service_name
            )
            
            logger.info(f"‚úÖ Traffic throttling conclu√≠do para {mitigation.service_name}")
            
            return {
                "success": True,
                "action": "traffic_throttling_activated",
                "service": mitigation.service_name,
                "rate_limit": throttling_result["rate_limit"],
                "queue_configured": queue_result["success"],
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    def _define_mitigation_steps(self, strategy: MitigationStrategy, prediction: FailurePrediction) -> Tuple[List[str], List[str], List[str]]:
        """Definir steps de prepara√ß√£o, execu√ß√£o e rollback"""
        
        if strategy == MitigationStrategy.HOT_STANDBY_REPLACEMENT:
            preparation = [
                "Validate standby instance requirements",
                "Check available resources",
                "Prepare load balancer configuration",
                "Validate health check endpoints"
            ]
            execution = [
                "Create standby instance",
                "Initialize standby service",
                "Validate standby health",
                "Switch traffic to standby",
                "Decommission original instance"
            ]
            rollback = [
                "Restore original instance",
                "Switch traffic back",
                "Validate original health",
                "Remove standby instance"
            ]
        
        elif strategy == MitigationStrategy.RESOURCE_SCALING:
            preparation = [
                "Analyze current resource utilization",
                "Calculate required resources",
                "Check resource availability",
                "Prepare scaling configuration"
            ]
            execution = [
                "Apply resource scaling",
                "Monitor scaling progress",
                "Validate new resource allocation",
                "Test service performance"
            ]
            rollback = [
                "Revert to original resource allocation",
                "Validate service stability",
                "Monitor for issues"
            ]
        
        else:
            # Default steps para outras estrat√©gias
            preparation = ["Prepare mitigation environment", "Validate prerequisites"]
            execution = ["Execute mitigation strategy", "Validate results"]
            rollback = ["Revert changes", "Restore original state"]
        
        return preparation, execution, rollback
    
    def _estimate_required_resources(self, strategy: MitigationStrategy, prediction: FailurePrediction) -> Dict[str, Any]:
        """Estimar recursos necess√°rios para mitiga√ß√£o"""
        
        if strategy == MitigationStrategy.HOT_STANDBY_REPLACEMENT:
            return {
                "instances": 1,
                "cpu": "1000m",
                "memory": "2Gi",
                "storage": "10Gi",
                "network_bandwidth": "100Mbps"
            }
        
        elif strategy == MitigationStrategy.RESOURCE_SCALING:
            if prediction.failure_type == FailureType.CPU_OVERLOAD:
                return {
                    "cpu": "2000m",
                    "memory": "4Gi"
                }
            elif prediction.failure_type == FailureType.MEMORY_LEAK:
                return {
                    "memory": "8Gi",
                    "cpu": "1500m"
                }
            else:
                return {
                    "instances": 2,
                    "cpu": "1500m",
                    "memory": "3Gi"
                }
        
        else:
            return {
                "cpu": "500m",
                "memory": "1Gi"
            }
    
    def _identify_dependencies(self, service_name: str, strategy: MitigationStrategy) -> List[str]:
        """Identificar depend√™ncias para mitiga√ß√£o"""
        
        # Mapeamento simplificado de depend√™ncias
        service_dependencies = {
            "rl-engine": ["ecosystem-platform"],
            "creative-studio": ["rl-engine"],
            "proactive-conversation": ["future-casting"],
            "future-casting": [],
            "ecosystem-platform": []
        }
        
        return service_dependencies.get(service_name, [])
    
    def _estimate_mitigation_duration(self, strategy: MitigationStrategy) -> int:
        """Estimar dura√ß√£o da mitiga√ß√£o em segundos"""
        
        durations = {
            MitigationStrategy.HOT_STANDBY_REPLACEMENT: 300,  # 5 minutos
            MitigationStrategy.GRACEFUL_RESTART: 120,        # 2 minutos
            MitigationStrategy.LOAD_REDISTRIBUTION: 180,     # 3 minutos
            MitigationStrategy.RESOURCE_SCALING: 240,        # 4 minutos
            MitigationStrategy.CIRCUIT_BREAKER_ACTIVATION: 60,  # 1 minuto
            MitigationStrategy.TRAFFIC_THROTTLING: 90        # 1.5 minutos
        }
        
        return durations.get(strategy, 180)
    
    async def _monitor_mitigation_result(self, mitigation: ProactiveMitigation):
        """Monitorar resultado da mitiga√ß√£o"""
        
        # Aguardar estabiliza√ß√£o
        await asyncio.sleep(10)
        
        logger.info(f"üìä Monitorando resultado da mitiga√ß√£o {mitigation.id}")
        
        # Em produ√ß√£o, verificaria m√©tricas reais do servi√ßo
        # para confirmar que a mitiga√ß√£o foi efetiva
    
    async def _attempt_mitigation_rollback(self, mitigation: ProactiveMitigation):
        """Tentar rollback da mitiga√ß√£o"""
        
        try:
            logger.info(f"üîÑ Tentando rollback da mitiga√ß√£o {mitigation.id}")
            
            for step in mitigation.rollback_steps:
                logger.info(f"  üìã Rollback: {step}")
                await asyncio.sleep(1)
            
            mitigation.status = PreventionStatus.ROLLBACK_REQUIRED
            
        except Exception as e:
            logger.error(f"‚ùå Falha no rollback da mitiga√ß√£o {mitigation.id}: {str(e)}")

# ============================================================================
# SIMULADOR DE INFRAESTRUTURA API
# ============================================================================

class InfrastructureAPISimulator:
    """Simulador de APIs de infraestrutura para desenvolvimento local"""
    
    def __init__(self):
        self.instances = {}
        self.load_balancers = {}
        self.circuit_breakers = {}
    
    async def create_standby_instance(self, service_name: str) -> Dict[str, Any]:
        """Simular cria√ß√£o de inst√¢ncia standby"""
        await asyncio.sleep(2)
        
        if random.random() > 0.1:  # 90% de sucesso
            instance_id = f"standby-{service_name}-{int(time.time())}"
            self.instances[instance_id] = {
                "service": service_name,
                "status": "running",
                "health": "healthy",
                "created_at": datetime.now()
            }
            
            return {
                "success": True,
                "instance_id": instance_id,
                "message": f"Standby instance created for {service_name}"
            }
        else:
            return {
                "success": False,
                "error": "Failed to create standby instance - insufficient resources"
            }
    
    async def validate_instance_health(self, instance_id: str) -> Dict[str, Any]:
        """Simular valida√ß√£o de sa√∫de da inst√¢ncia"""
        await asyncio.sleep(1)
        
        if instance_id in self.instances:
            return {
                "healthy": random.random() > 0.05,  # 95% de sucesso
                "health_score": random.uniform(85, 98),
                "response_time": random.uniform(50, 150)
            }
        else:
            return {"healthy": False, "error": "Instance not found"}
    
    async def switch_traffic_to_standby(self, service_name: str, standby_instance_id: str) -> Dict[str, Any]:
        """Simular mudan√ßa de tr√°fego para standby"""
        await asyncio.sleep(1)
        
        if random.random() > 0.05:  # 95% de sucesso
            return {
                "success": True,
                "message": f"Traffic switched to standby {standby_instance_id}",
                "traffic_percentage": 100
            }
        else:
            return {
                "success": False,
                "error": "Failed to switch traffic - load balancer error"
            }
    
    async def decommission_original_instance(self, service_name: str) -> Dict[str, Any]:
        """Simular descomissionamento da inst√¢ncia original"""
        await asyncio.sleep(1)
        
        return {
            "success": True,
            "message": f"Original instance decommissioned for {service_name}"
        }
    
    async def drain_connections(self, service_name: str) -> Dict[str, Any]:
        """Simular drenagem de conex√µes"""
        await asyncio.sleep(2)
        
        return {
            "success": True,
            "connections_drained": random.randint(10, 100),
            "drain_time": random.uniform(1, 3)
        }
    
    async def restart_service_gracefully(self, service_name: str) -> Dict[str, Any]:
        """Simular restart graceful"""
        await asyncio.sleep(3)
        
        if random.random() > 0.05:  # 95% de sucesso
            return {
                "success": True,
                "restart_time": random.uniform(2, 5),
                "message": f"Service {service_name} restarted gracefully"
            }
        else:
            return {
                "success": False,
                "error": "Graceful restart failed - service dependencies not ready"
            }
    
    async def validate_service_health(self, service_name: str) -> Dict[str, Any]:
        """Simular valida√ß√£o de sa√∫de do servi√ßo"""
        await asyncio.sleep(1)
        
        return {
            "healthy": random.random() > 0.1,  # 90% de sucesso
            "health_score": random.uniform(80, 95),
            "response_time": random.uniform(50, 200)
        }
    
    async def analyze_current_load(self, service_name: str) -> Dict[str, Any]:
        """Simular an√°lise de carga atual"""
        await asyncio.sleep(1)
        
        return {
            "load_distribution": {
                "instance_1": random.uniform(60, 90),
                "instance_2": random.uniform(20, 40),
                "instance_3": random.uniform(30, 50)
            },
            "total_load": random.uniform(200, 400),
            "bottlenecks": ["instance_1"]
        }
    
    async def create_redistribution_plan(self, service_name: str, current_load: Dict[str, float]) -> Dict[str, Any]:
        """Simular cria√ß√£o de plano de redistribui√ß√£o"""
        await asyncio.sleep(1)
        
        return {
            "redistribution_plan": {
                "instance_1": 50,  # Reduzir carga
                "instance_2": 45,  # Aumentar carga
                "instance_3": 45   # Aumentar carga
            },
            "expected_improvement": 30
        }
    
    async def execute_load_redistribution(self, plan: Dict[str, Any]) -> Dict[str, Any]:
        """Simular execu√ß√£o de redistribui√ß√£o"""
        await asyncio.sleep(2)
        
        return {
            "success": random.random() > 0.1,  # 90% de sucesso
            "redistribution_completed": True,
            "new_load_distribution": plan["redistribution_plan"]
        }
    
    async def validate_load_distribution(self, service_name: str) -> Dict[str, Any]:
        """Simular valida√ß√£o de distribui√ß√£o"""
        await asyncio.sleep(1)
        
        return {
            "load_distribution": {
                "instance_1": 50,
                "instance_2": 45,
                "instance_3": 45
            },
            "load_balance_improvement": random.uniform(25, 35),
            "performance_improvement": random.uniform(15, 25)
        }
    
    async def scale_instances(self, service_name: str, target_instances: int) -> Dict[str, Any]:
        """Simular scaling horizontal"""
        await asyncio.sleep(3)
        
        return {
            "success": random.random() > 0.1,  # 90% de sucesso
            "resources_allocated": {
                "instances": target_instances,
                "total_cpu": f"{target_instances * 1000}m",
                "total_memory": f"{target_instances * 2}Gi"
            }
        }
    
    async def scale_resources(self, service_name: str, cpu_limit: str, memory_limit: str) -> Dict[str, Any]:
        """Simular scaling vertical"""
        await asyncio.sleep(2)
        
        return {
            "success": random.random() > 0.1,  # 90% de sucesso
            "resources_allocated": {
                "cpu": cpu_limit,
                "memory": memory_limit
            }
        }
    
    async def validate_scaling_result(self, service_name: str, scaling_type: str) -> Dict[str, Any]:
        """Simular valida√ß√£o de scaling"""
        await asyncio.sleep(1)
        
        return {
            "performance_improvement": random.uniform(20, 40),
            "resource_utilization": random.uniform(60, 80),
            "scaling_effective": True
        }
    
    async def activate_circuit_breaker(self, service_name: str, dependencies: List[str]) -> Dict[str, Any]:
        """Simular ativa√ß√£o de circuit breaker"""
        await asyncio.sleep(1)
        
        return {
            "success": True,
            "protected_dependencies": dependencies,
            "circuit_breaker_active": True
        }
    
    async def configure_fallback_responses(self, service_name: str) -> Dict[str, Any]:
        """Simular configura√ß√£o de fallback"""
        await asyncio.sleep(1)
        
        return {
            "success": True,
            "fallback_configured": True,
            "fallback_endpoints": ["/health", "/status"]
        }
    
    async def implement_rate_limiting(self, service_name: str, rate_limit: str) -> Dict[str, Any]:
        """Simular implementa√ß√£o de rate limiting"""
        await asyncio.sleep(1)
        
        return {
            "success": True,
            "rate_limit": rate_limit,
            "rate_limiting_active": True
        }
    
    async def configure_request_queue(self, service_name: str) -> Dict[str, Any]:
        """Simular configura√ß√£o de queue"""
        await asyncio.sleep(1)
        
        return {
            "success": True,
            "queue_configured": True,
            "queue_size": 1000
        }

# ============================================================================
# MAIN - EXEMPLO DE USO
# ============================================================================

async def main():
    """Exemplo de uso do Proactive Mitigation Engine"""
    
    logger.info("üõ°Ô∏è Iniciando Proactive Mitigation Engine v4.0")
    
    # Criar engines
    prediction_engine = FailurePredictionEngine()
    mitigation_orchestrator = ProactiveMitigationOrchestrator()
    
    # Simular dados de m√©tricas hist√≥ricas
    sample_metrics = [
        {"health_score": 85, "response_time_ms": 100, "cpu_usage_percent": 70, "memory_usage_percent": 60, "error_rate_percent": 2, "throughput_rps": 2.0, "anomaly_score": 1.5},
        {"health_score": 82, "response_time_ms": 120, "cpu_usage_percent": 75, "memory_usage_percent": 65, "error_rate_percent": 3, "throughput_rps": 1.8, "anomaly_score": 2.0},
        {"health_score": 78, "response_time_ms": 150, "cpu_usage_percent": 80, "memory_usage_percent": 70, "error_rate_percent": 5, "throughput_rps": 1.5, "anomaly_score": 3.0},
        {"health_score": 75, "response_time_ms": 180, "cpu_usage_percent": 85, "memory_usage_percent": 75, "error_rate_percent": 8, "throughput_rps": 1.2, "anomaly_score": 4.0},
        {"health_score": 70, "response_time_ms": 220, "cpu_usage_percent": 90, "memory_usage_percent": 80, "error_rate_percent": 12, "throughput_rps": 1.0, "anomaly_score": 5.0}
    ]
    
    # Analisar tend√™ncias
    trend = await prediction_engine.analyze_service_trends("test-service", sample_metrics)
    
    logger.info(f"üìä Tend√™ncia analisada: failure_probability={trend.failure_probability:.2f}")
    
    # Predizer falhas
    predictions = await prediction_engine.predict_failures(trend)
    
    for prediction in predictions:
        logger.info(f"‚ö†Ô∏è Falha predita: {prediction.failure_type.value} em {prediction.time_to_failure_minutes} minutos (confian√ßa: {prediction.confidence:.2f})")
        
        # Criar plano de mitiga√ß√£o
        mitigation = await mitigation_orchestrator.create_mitigation_plan(prediction)
        
        logger.info(f"üõ°Ô∏è Plano de mitiga√ß√£o criado: {mitigation.strategy.value}")
        
        # Executar mitiga√ß√£o se confian√ßa for alta
        if prediction.confidence > 0.8:
            result = await mitigation_orchestrator.execute_mitigation(mitigation)
            
            if result["success"]:
                logger.info(f"‚úÖ Mitiga√ß√£o executada com sucesso")
            else:
                logger.error(f"‚ùå Mitiga√ß√£o falhou: {result.get('error', 'Unknown error')}")

if __name__ == "__main__":
    asyncio.run(main())

